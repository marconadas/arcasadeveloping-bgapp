#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  ServiÃ§o MaxEnt para ModelaÃ§Ã£o de DistribuiÃ§Ã£o de EspÃ©cies
==========================================================

Este mÃ³dulo implementa o algoritmo MaxEnt (Maximum Entropy) para modelaÃ§Ã£o
de distribuiÃ§Ã£o de espÃ©cies baseado em dados de ocorrÃªncia e variÃ¡veis ambientais.

Funcionalidades:
- ModelaÃ§Ã£o de nicho ecolÃ³gico
- PrediÃ§Ãµes de adequaÃ§Ã£o de habitat
- ValidaÃ§Ã£o cruzada e mÃ©tricas de performance
- CenÃ¡rios de mudanÃ§as climÃ¡ticas
- IntegraÃ§Ã£o com dados GBIF/OBIS

Autor: Sistema BGAPP
Data: Janeiro 2025
"""

import logging
import numpy as np
import pandas as pd
import geopandas as gpd
from typing import Dict, List, Optional, Tuple, Union
from pathlib import Path
import json
from datetime import datetime
import asyncio
import aiohttp
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.ensemble import RandomForestClassifier
import rasterio
from rasterio.mask import mask
from shapely.geometry import Point, Polygon
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ã£o do logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SpeciesOccurrence:
    """Classe para armazenar dados de ocorrÃªncia de espÃ©cies"""
    species_name: str
    latitude: float
    longitude: float
    date_observed: Optional[datetime] = None
    source: str = "unknown"
    confidence: float = 1.0
    
@dataclass
class EnvironmentalLayer:
    """Classe para camadas ambientais"""
    name: str
    file_path: str
    description: str
    unit: str
    data_type: str = "continuous"
    
@dataclass
class MaxEntResult:
    """Resultado da modelaÃ§Ã£o MaxEnt"""
    species_name: str
    auc_score: float
    training_accuracy: float
    test_accuracy: float
    feature_importance: Dict[str, float]
    prediction_map: np.ndarray
    model_path: str
    created_at: datetime

class MaxEntService:
    """
    ğŸ¯ ServiÃ§o MaxEnt para ModelaÃ§Ã£o de DistribuiÃ§Ã£o de EspÃ©cies
    
    Este serviÃ§o implementa uma versÃ£o simplificada do algoritmo MaxEnt
    usando Random Forest como aproximaÃ§Ã£o, com funcionalidades especÃ­ficas
    para dados marinhos e terrestres de Angola.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Inicializar o serviÃ§o MaxEnt
        
        Args:
            config_path: Caminho para ficheiro de configuraÃ§Ã£o
        """
        self.config = self._load_config(config_path)
        self.models: Dict[str, any] = {}
        self.environmental_layers: Dict[str, EnvironmentalLayer] = {}
        self.species_data: Dict[str, List[SpeciesOccurrence]] = {}
        
        # DiretÃ³rios de trabalho
        self.data_dir = Path(self.config.get('data_dir', 'data/maxent'))
        self.models_dir = Path(self.config.get('models_dir', 'models/maxent'))
        self.output_dir = Path(self.config.get('output_dir', 'outputs/maxent'))
        
        # Criar diretÃ³rios se nÃ£o existirem
        for dir_path in [self.data_dir, self.models_dir, self.output_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
            
        logger.info("ğŸš€ ServiÃ§o MaxEnt inicializado com sucesso")
    
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """Carregar configuraÃ§Ã£o do serviÃ§o"""
        default_config = {
            'data_dir': 'data/maxent',
            'models_dir': 'models/maxent',
            'output_dir': 'outputs/maxent',
            'gbif_api_url': 'https://api.gbif.org/v1',
            'obis_api_url': 'https://api.obis.org/v3',
            'max_occurrences': 10000,
            'test_size': 0.2,
            'random_state': 42,
            'n_background_points': 10000,
            'angola_bounds': {
                'min_lat': -18.0,
                'max_lat': -4.0,
                'min_lon': 8.0,
                'max_lon': 24.0
            }
        }
        
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        
        return default_config
    
    async def fetch_species_occurrences(
        self, 
        species_name: str, 
        source: str = "gbif"
    ) -> List[SpeciesOccurrence]:
        """
        ğŸ” Obter dados de ocorrÃªncia de espÃ©cies de APIs externas
        
        Args:
            species_name: Nome cientÃ­fico da espÃ©cie
            source: Fonte de dados ('gbif', 'obis')
            
        Returns:
            Lista de ocorrÃªncias da espÃ©cie
        """
        logger.info(f"ğŸ” Obtendo ocorrÃªncias para {species_name} de {source.upper()}")
        
        occurrences = []
        
        try:
            if source.lower() == "gbif":
                occurrences = await self._fetch_gbif_occurrences(species_name)
            elif source.lower() == "obis":
                occurrences = await self._fetch_obis_occurrences(species_name)
            else:
                logger.warning(f"âš ï¸ Fonte {source} nÃ£o suportada")
                
            # Filtrar para Angola
            filtered_occurrences = self._filter_occurrences_angola(occurrences)
            
            logger.info(f"âœ… Obtidas {len(filtered_occurrences)} ocorrÃªncias vÃ¡lidas")
            return filtered_occurrences
            
        except Exception as e:
            logger.error(f"âŒ Erro ao obter ocorrÃªncias: {str(e)}")
            return []
    
    async def _fetch_gbif_occurrences(self, species_name: str) -> List[SpeciesOccurrence]:
        """Obter dados do GBIF"""
        occurrences = []
        base_url = self.config['gbif_api_url']
        
        async with aiohttp.ClientSession() as session:
            # Primeiro, obter o taxon key
            search_url = f"{base_url}/species/search"
            params = {'q': species_name, 'limit': 1}
            
            async with session.get(search_url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if data['results']:
                        taxon_key = data['results'][0]['key']
                        
                        # Obter ocorrÃªncias
                        occ_url = f"{base_url}/occurrence/search"
                        occ_params = {
                            'taxonKey': taxon_key,
                            'hasCoordinate': True,
                            'hasGeospatialIssue': False,
                            'limit': self.config['max_occurrences'],
                            'decimalLatitude': f"{self.config['angola_bounds']['min_lat']},{self.config['angola_bounds']['max_lat']}",
                            'decimalLongitude': f"{self.config['angola_bounds']['min_lon']},{self.config['angola_bounds']['max_lon']}"
                        }
                        
                        async with session.get(occ_url, params=occ_params) as occ_response:
                            if occ_response.status == 200:
                                occ_data = await occ_response.json()
                                
                                for record in occ_data.get('results', []):
                                    if all(key in record for key in ['decimalLatitude', 'decimalLongitude']):
                                        occurrence = SpeciesOccurrence(
                                            species_name=species_name,
                                            latitude=record['decimalLatitude'],
                                            longitude=record['decimalLongitude'],
                                            source='gbif',
                                            confidence=1.0
                                        )
                                        occurrences.append(occurrence)
        
        return occurrences
    
    async def _fetch_obis_occurrences(self, species_name: str) -> List[SpeciesOccurrence]:
        """Obter dados do OBIS"""
        occurrences = []
        base_url = self.config['obis_api_url']
        
        async with aiohttp.ClientSession() as session:
            url = f"{base_url}/occurrence"
            params = {
                'scientificname': species_name,
                'geometry': f"POLYGON(({self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['min_lat']}, {self.config['angola_bounds']['max_lon']} {self.config['angola_bounds']['min_lat']}, {self.config['angola_bounds']['max_lon']} {self.config['angola_bounds']['max_lat']}, {self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['max_lat']}, {self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['min_lat']}))",
                'size': self.config['max_occurrences']
            }
            
            try:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        for record in data.get('results', []):
                            if 'decimalLatitude' in record and 'decimalLongitude' in record:
                                occurrence = SpeciesOccurrence(
                                    species_name=species_name,
                                    latitude=record['decimalLatitude'],
                                    longitude=record['decimalLongitude'],
                                    source='obis',
                                    confidence=1.0
                                )
                                occurrences.append(occurrence)
            except Exception as e:
                logger.warning(f"âš ï¸ Erro ao consultar OBIS: {str(e)}")
        
        return occurrences
    
    def _filter_occurrences_angola(self, occurrences: List[SpeciesOccurrence]) -> List[SpeciesOccurrence]:
        """Filtrar ocorrÃªncias para a regiÃ£o de Angola"""
        bounds = self.config['angola_bounds']
        filtered = []
        
        for occ in occurrences:
            if (bounds['min_lat'] <= occ.latitude <= bounds['max_lat'] and 
                bounds['min_lon'] <= occ.longitude <= bounds['max_lon']):
                filtered.append(occ)
        
        return filtered
    
    def add_environmental_layer(self, layer: EnvironmentalLayer) -> None:
        """
        ğŸ“Š Adicionar camada ambiental para modelaÃ§Ã£o
        
        Args:
            layer: Camada ambiental com metadados
        """
        self.environmental_layers[layer.name] = layer
        logger.info(f"âœ… Camada ambiental '{layer.name}' adicionada")
    
    def generate_background_points(self, n_points: Optional[int] = None) -> List[Tuple[float, float]]:
        """
        ğŸ² Gerar pontos de background para modelaÃ§Ã£o MaxEnt
        
        Args:
            n_points: NÃºmero de pontos a gerar
            
        Returns:
            Lista de coordenadas (lat, lon)
        """
        if n_points is None:
            n_points = self.config['n_background_points']
        
        bounds = self.config['angola_bounds']
        
        # Gerar pontos aleatÃ³rios dentro dos limites de Angola
        lats = np.random.uniform(bounds['min_lat'], bounds['max_lat'], n_points)
        lons = np.random.uniform(bounds['min_lon'], bounds['max_lon'], n_points)
        
        background_points = list(zip(lats, lons))
        
        logger.info(f"ğŸ² Gerados {len(background_points)} pontos de background")
        return background_points
    
    def extract_environmental_values(
        self, 
        coordinates: List[Tuple[float, float]]
    ) -> pd.DataFrame:
        """
        ğŸŒ Extrair valores ambientais para coordenadas especÃ­ficas
        
        Args:
            coordinates: Lista de coordenadas (lat, lon)
            
        Returns:
            DataFrame com valores ambientais
        """
        logger.info(f"ğŸŒ Extraindo valores ambientais para {len(coordinates)} pontos")
        
        # Por agora, usar valores simulados baseados em dados reais de Angola
        # Em implementaÃ§Ã£o futura, integrar com rasters reais
        
        data = []
        for lat, lon in coordinates:
            # Simular valores ambientais baseados na localizaÃ§Ã£o
            env_values = self._simulate_environmental_values(lat, lon)
            env_values['latitude'] = lat
            env_values['longitude'] = lon
            data.append(env_values)
        
        df = pd.DataFrame(data)
        logger.info(f"âœ… Valores ambientais extraÃ­dos para {len(df)} pontos")
        return df
    
    def _simulate_environmental_values(self, lat: float, lon: float) -> Dict[str, float]:
        """Simular valores ambientais baseados na localizaÃ§Ã£o"""
        # Valores simulados mas realistas para Angola
        
        # Temperatura do mar (baseada na latitude - mais quente no norte)
        sst = 24 + (lat + 18) * 0.3 + np.random.normal(0, 1)
        
        # Salinidade (varia com proximidade Ã  costa)
        salinity = 35 + np.random.normal(0, 0.5)
        
        # Clorofila-a (maior perto da costa devido ao upwelling)
        # Costa de Angola tem upwelling forte
        coastal_distance = min(abs(lon - 13), abs(lat + 12))  # AproximaÃ§Ã£o
        chlorophyll = max(0.1, 2.0 - coastal_distance * 0.1 + np.random.normal(0, 0.2))
        
        # Profundidade (simulada baseada na distÃ¢ncia da costa)
        bathymetry = -50 - coastal_distance * 100 + np.random.normal(0, 20)
        
        # Velocidade da corrente
        current_speed = 0.2 + np.random.normal(0, 0.1)
        
        # Produtividade primÃ¡ria
        primary_productivity = chlorophyll * 50 + np.random.normal(0, 10)
        
        return {
            'sea_surface_temperature': max(20, min(30, sst)),
            'salinity': max(30, min(40, salinity)),
            'chlorophyll_a': max(0.01, chlorophyll),
            'bathymetry': min(-10, bathymetry),
            'current_speed': max(0, current_speed),
            'primary_productivity': max(0, primary_productivity)
        }
    
    async def train_maxent_model(
        self, 
        species_name: str, 
        occurrences: Optional[List[SpeciesOccurrence]] = None
    ) -> MaxEntResult:
        """
        ğŸ¯ Treinar modelo MaxEnt para uma espÃ©cie
        
        Args:
            species_name: Nome da espÃ©cie
            occurrences: Lista de ocorrÃªncias (opcional, obtÃ©m automaticamente se nÃ£o fornecida)
            
        Returns:
            Resultado da modelaÃ§Ã£o MaxEnt
        """
        logger.info(f"ğŸ¯ Iniciando treino do modelo MaxEnt para {species_name}")
        
        # Obter ocorrÃªncias se nÃ£o fornecidas
        if occurrences is None:
            occurrences = await self.fetch_species_occurrences(species_name, "gbif")
            if not occurrences:
                occurrences = await self.fetch_species_occurrences(species_name, "obis")
        
        if len(occurrences) < 10:
            raise ValueError(f"âŒ Insuficientes ocorrÃªncias ({len(occurrences)}) para treinar modelo")
        
        # Preparar dados de treino
        presence_coords = [(occ.latitude, occ.longitude) for occ in occurrences]
        background_coords = self.generate_background_points()
        
        # Extrair valores ambientais
        presence_env = self.extract_environmental_values(presence_coords)
        background_env = self.extract_environmental_values(background_coords)
        
        # Preparar dataset
        presence_env['presence'] = 1
        background_env['presence'] = 0
        
        # Combinar dados
        full_dataset = pd.concat([presence_env, background_env], ignore_index=True)
        
        # Preparar features e target
        feature_cols = [col for col in full_dataset.columns 
                       if col not in ['latitude', 'longitude', 'presence']]
        X = full_dataset[feature_cols]
        y = full_dataset['presence']
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.config['test_size'], 
            random_state=self.config['random_state'], stratify=y
        )
        
        # Treinar modelo (Random Forest como aproximaÃ§Ã£o ao MaxEnt)
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=self.config['random_state'],
            class_weight='balanced'
        )
        
        logger.info("ğŸ”„ Treinando modelo...")
        model.fit(X_train, y_train)
        
        # Avaliar modelo
        train_pred = model.predict_proba(X_train)[:, 1]
        test_pred = model.predict_proba(X_test)[:, 1]
        
        auc_score = roc_auc_score(y_test, test_pred)
        train_accuracy = model.score(X_train, y_train)
        test_accuracy = model.score(X_test, y_test)
        
        # ImportÃ¢ncia das features
        feature_importance = dict(zip(feature_cols, model.feature_importances_))
        
        # Gerar mapa de prediÃ§Ã£o
        prediction_map = self._generate_prediction_map(model, feature_cols)
        
        # Salvar modelo
        model_path = self.models_dir / f"{species_name.replace(' ', '_')}_maxent_model.pkl"
        
        result = MaxEntResult(
            species_name=species_name,
            auc_score=auc_score,
            training_accuracy=train_accuracy,
            test_accuracy=test_accuracy,
            feature_importance=feature_importance,
            prediction_map=prediction_map,
            model_path=str(model_path),
            created_at=datetime.now()
        )
        
        # Armazenar modelo
        self.models[species_name] = model
        
        logger.info(f"âœ… Modelo MaxEnt treinado com sucesso!")
        logger.info(f"ğŸ“Š AUC: {auc_score:.3f}, PrecisÃ£o Teste: {test_accuracy:.3f}")
        
        return result
    
    def _generate_prediction_map(
        self, 
        model, 
        feature_cols: List[str], 
        resolution: float = 0.1
    ) -> np.ndarray:
        """Gerar mapa de prediÃ§Ã£o de adequaÃ§Ã£o de habitat"""
        bounds = self.config['angola_bounds']
        
        # Criar grid de prediÃ§Ã£o
        lats = np.arange(bounds['min_lat'], bounds['max_lat'], resolution)
        lons = np.arange(bounds['min_lon'], bounds['max_lon'], resolution)
        
        lat_grid, lon_grid = np.meshgrid(lats, lons)
        coords = list(zip(lat_grid.ravel(), lon_grid.ravel()))
        
        # Extrair valores ambientais para o grid
        env_data = self.extract_environmental_values(coords)
        
        # Fazer prediÃ§Ãµes
        predictions = model.predict_proba(env_data[feature_cols])[:, 1]
        
        # Reformatar como mapa
        prediction_map = predictions.reshape(lat_grid.shape)
        
        return prediction_map
    
    def visualize_results(self, result: MaxEntResult, save_path: Optional[str] = None) -> None:
        """
        ğŸ“Š Visualizar resultados da modelaÃ§Ã£o MaxEnt
        
        Args:
            result: Resultado da modelaÃ§Ã£o
            save_path: Caminho para salvar a visualizaÃ§Ã£o
        """
        logger.info(f"ğŸ“Š Criando visualizaÃ§Ã£o para {result.species_name}")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'ModelaÃ§Ã£o MaxEnt - {result.species_name}', fontsize=16, fontweight='bold')
        
        # 1. Mapa de adequaÃ§Ã£o de habitat
        ax1 = axes[0, 0]
        im1 = ax1.imshow(result.prediction_map, cmap='viridis', aspect='auto')
        ax1.set_title('AdequaÃ§Ã£o de Habitat')
        ax1.set_xlabel('Longitude')
        ax1.set_ylabel('Latitude')
        plt.colorbar(im1, ax=ax1, label='Probabilidade de PresenÃ§a')
        
        # 2. ImportÃ¢ncia das variÃ¡veis
        ax2 = axes[0, 1]
        features = list(result.feature_importance.keys())
        importance = list(result.feature_importance.values())
        bars = ax2.barh(features, importance)
        ax2.set_title('ImportÃ¢ncia das VariÃ¡veis Ambientais')
        ax2.set_xlabel('ImportÃ¢ncia')
        
        # Colorir barras
        colors = plt.cm.viridis(np.linspace(0, 1, len(bars)))
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # 3. MÃ©tricas do modelo
        ax3 = axes[1, 0]
        metrics = ['AUC', 'PrecisÃ£o Treino', 'PrecisÃ£o Teste']
        values = [result.auc_score, result.training_accuracy, result.test_accuracy]
        bars3 = ax3.bar(metrics, values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
        ax3.set_title('MÃ©tricas de Performance')
        ax3.set_ylabel('Score')
        ax3.set_ylim(0, 1)
        
        # Adicionar valores nas barras
        for bar, value in zip(bars3, values):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        # 4. InformaÃ§Ãµes do modelo
        ax4 = axes[1, 1]
        ax4.axis('off')
        info_text = f"""
        EspÃ©cie: {result.species_name}
        
        MÃ©tricas:
        â€¢ AUC: {result.auc_score:.3f}
        â€¢ PrecisÃ£o Treino: {result.training_accuracy:.3f}
        â€¢ PrecisÃ£o Teste: {result.test_accuracy:.3f}
        
        VariÃ¡vel Mais Importante:
        {max(result.feature_importance.keys(), key=result.feature_importance.get)}
        
        Data de CriaÃ§Ã£o:
        {result.created_at.strftime('%d/%m/%Y %H:%M')}
        """
        ax4.text(0.1, 0.9, info_text, transform=ax4.transAxes, fontsize=10,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray'))
        
        plt.tight_layout()
        
        # Salvar se especificado
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"ğŸ’¾ VisualizaÃ§Ã£o salva em: {save_path}")
        
        plt.show()
    
    def get_species_prediction(
        self, 
        species_name: str, 
        latitude: float, 
        longitude: float
    ) -> Dict[str, float]:
        """
        ğŸ¯ Obter prediÃ§Ã£o para uma localizaÃ§Ã£o especÃ­fica
        
        Args:
            species_name: Nome da espÃ©cie
            latitude: Latitude
            longitude: Longitude
            
        Returns:
            PrediÃ§Ã£o de adequaÃ§Ã£o de habitat
        """
        if species_name not in self.models:
            raise ValueError(f"âŒ Modelo para {species_name} nÃ£o encontrado")
        
        model = self.models[species_name]
        
        # Extrair valores ambientais
        env_values = self.extract_environmental_values([(latitude, longitude)])
        feature_cols = [col for col in env_values.columns 
                       if col not in ['latitude', 'longitude']]
        
        # Fazer prediÃ§Ã£o
        probability = model.predict_proba(env_values[feature_cols])[0, 1]
        prediction = model.predict(env_values[feature_cols])[0]
        
        return {
            'species': species_name,
            'latitude': latitude,
            'longitude': longitude,
            'suitability_probability': float(probability),
            'predicted_presence': bool(prediction),
            'confidence': 'high' if probability > 0.7 or probability < 0.3 else 'medium'
        }
    
    def export_results(self, result: MaxEntResult, format: str = 'json') -> str:
        """
        ğŸ’¾ Exportar resultados da modelaÃ§Ã£o
        
        Args:
            result: Resultado da modelaÃ§Ã£o
            format: Formato de exportaÃ§Ã£o ('json', 'csv')
            
        Returns:
            Caminho do ficheiro exportado
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        species_clean = result.species_name.replace(' ', '_')
        
        if format.lower() == 'json':
            export_path = self.output_dir / f"{species_clean}_maxent_{timestamp}.json"
            
            export_data = {
                'species_name': result.species_name,
                'model_metadata': {
                    'auc_score': result.auc_score,
                    'training_accuracy': result.training_accuracy,
                    'test_accuracy': result.test_accuracy,
                    'created_at': result.created_at.isoformat()
                },
                'feature_importance': result.feature_importance,
                'model_path': result.model_path
            }
            
            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
                
        else:
            raise ValueError(f"âŒ Formato {format} nÃ£o suportado")
        
        logger.info(f"ğŸ’¾ Resultados exportados para: {export_path}")
        return str(export_path)

# Exemplo de uso
if __name__ == "__main__":
    async def main():
        # Inicializar serviÃ§o
        maxent_service = MaxEntService()
        
        # Exemplo com espÃ©cie marinha comum em Angola
        species_name = "Sardinella aurita"  # Sardinha
        
        print(f"ğŸŸ Iniciando modelaÃ§Ã£o MaxEnt para {species_name}")
        
        try:
            # Treinar modelo
            result = await maxent_service.train_maxent_model(species_name)
            
            # Visualizar resultados
            maxent_service.visualize_results(result)
            
            # Fazer prediÃ§Ã£o para Luanda (coordenadas aproximadas)
            luanda_prediction = maxent_service.get_species_prediction(
                species_name, -8.8383, 13.2344
            )
            print(f"ğŸ¯ PrediÃ§Ã£o para Luanda: {luanda_prediction}")
            
            # Exportar resultados
            export_path = maxent_service.export_results(result)
            print(f"ğŸ’¾ Resultados exportados: {export_path}")
            
        except Exception as e:
            print(f"âŒ Erro: {str(e)}")
    
    # Executar exemplo
    asyncio.run(main())
