#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
🧠 Serviço MaxEnt para Modelação de Distribuição de Espécies
==========================================================

Este módulo implementa o algoritmo MaxEnt (Maximum Entropy) para modelação
de distribuição de espécies baseado em dados de ocorrência e variáveis ambientais.

Funcionalidades:
- Modelação de nicho ecológico
- Predições de adequação de habitat
- Validação cruzada e métricas de performance
- Cenários de mudanças climáticas
- Integração com dados GBIF/OBIS

Autor: Sistema BGAPP
Data: Janeiro 2025
"""

import logging
import numpy as np
import pandas as pd
import geopandas as gpd
from typing import Dict, List, Optional, Tuple, Union
from pathlib import Path
import json
from datetime import datetime
import asyncio
import aiohttp
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.ensemble import RandomForestClassifier
import rasterio
from rasterio.mask import mask
from shapely.geometry import Point, Polygon
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import warnings
from bgapp.core.logger import logger
warnings.filterwarnings('ignore')

# Configuração do logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SpeciesOccurrence:
    """Classe para armazenar dados de ocorrência de espécies"""
    species_name: str
    latitude: float
    longitude: float
    date_observed: Optional[datetime] = None
    source: str = "unknown"
    confidence: float = 1.0
    
@dataclass
class EnvironmentalLayer:
    """Classe para camadas ambientais"""
    name: str
    file_path: str
    description: str
    unit: str
    data_type: str = "continuous"
    
@dataclass
class MaxEntResult:
    """Resultado da modelação MaxEnt"""
    species_name: str
    auc_score: float
    training_accuracy: float
    test_accuracy: float
    feature_importance: Dict[str, float]
    prediction_map: np.ndarray
    model_path: str
    created_at: datetime

class MaxEntService:
    """
    🎯 Serviço MaxEnt para Modelação de Distribuição de Espécies
    
    Este serviço implementa uma versão simplificada do algoritmo MaxEnt
    usando Random Forest como aproximação, com funcionalidades específicas
    para dados marinhos e terrestres de Angola.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Inicializar o serviço MaxEnt
        
        Args:
            config_path: Caminho para ficheiro de configuração
        """
        self.config = self._load_config(config_path)
        self.models: Dict[str, any] = {}
        self.environmental_layers: Dict[str, EnvironmentalLayer] = {}
        self.species_data: Dict[str, List[SpeciesOccurrence]] = {}
        
        # Diretórios de trabalho
        self.data_dir = Path(self.config.get('data_dir', 'data/maxent'))
        self.models_dir = Path(self.config.get('models_dir', 'models/maxent'))
        self.output_dir = Path(self.config.get('output_dir', 'outputs/maxent'))
        
        # Criar diretórios se não existirem
        for dir_path in [self.data_dir, self.models_dir, self.output_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
            
        logger.info("🚀 Serviço MaxEnt inicializado com sucesso")
    
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """Carregar configuração do serviço"""
        default_config = {
            'data_dir': 'data/maxent',
            'models_dir': 'models/maxent',
            'output_dir': 'outputs/maxent',
            'gbif_api_url': 'https://api.gbif.org/v1',
            'obis_api_url': 'https://api.obis.org/v3',
            'max_occurrences': 10000,
            'test_size': 0.2,
            'random_state': 42,
            'n_background_points': 10000,
            'angola_bounds': {
                'min_lat': -18.0,
                'max_lat': -4.0,
                'min_lon': 8.0,
                'max_lon': 24.0
            }
        }
        
        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                default_config.update(user_config)
        
        return default_config
    
    async def fetch_species_occurrences(
        self, 
        species_name: str, 
        source: str = "gbif"
    ) -> List[SpeciesOccurrence]:
        """
        🔍 Obter dados de ocorrência de espécies de APIs externas
        
        Args:
            species_name: Nome científico da espécie
            source: Fonte de dados ('gbif', 'obis')
            
        Returns:
            Lista de ocorrências da espécie
        """
        logger.info(f"🔍 Obtendo ocorrências para {species_name} de {source.upper()}")
        
        occurrences = []
        
        try:
            if source.lower() == "gbif":
                occurrences = await self._fetch_gbif_occurrences(species_name)
            elif source.lower() == "obis":
                occurrences = await self._fetch_obis_occurrences(species_name)
            else:
                logger.warning(f"⚠️ Fonte {source} não suportada")
                
            # Filtrar para Angola
            filtered_occurrences = self._filter_occurrences_angola(occurrences)
            
            logger.info(f"✅ Obtidas {len(filtered_occurrences)} ocorrências válidas")
            return filtered_occurrences
            
        except Exception as e:
            logger.error(f"❌ Erro ao obter ocorrências: {str(e)}")
            return []
    
    async def _fetch_gbif_occurrences(self, species_name: str) -> List[SpeciesOccurrence]:
        """Obter dados do GBIF"""
        occurrences = []
        base_url = self.config['gbif_api_url']
        
        async with aiohttp.ClientSession() as session:
            # Primeiro, obter o taxon key
            search_url = f"{base_url}/species/search"
            params = {'q': species_name, 'limit': 1}
            
            async with session.get(search_url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if data['results']:
                        taxon_key = data['results'][0]['key']
                        
                        # Obter ocorrências
                        occ_url = f"{base_url}/occurrence/search"
                        occ_params = {
                            'taxonKey': taxon_key,
                            'hasCoordinate': True,
                            'hasGeospatialIssue': False,
                            'limit': self.config['max_occurrences'],
                            'decimalLatitude': f"{self.config['angola_bounds']['min_lat']},{self.config['angola_bounds']['max_lat']}",
                            'decimalLongitude': f"{self.config['angola_bounds']['min_lon']},{self.config['angola_bounds']['max_lon']}"
                        }
                        
                        async with session.get(occ_url, params=occ_params) as occ_response:
                            if occ_response.status == 200:
                                occ_data = await occ_response.json()
                                
                                for record in occ_data.get('results', []):
                                    if all(key in record for key in ['decimalLatitude', 'decimalLongitude']):
                                        occurrence = SpeciesOccurrence(
                                            species_name=species_name,
                                            latitude=record['decimalLatitude'],
                                            longitude=record['decimalLongitude'],
                                            source='gbif',
                                            confidence=1.0
                                        )
                                        occurrences.append(occurrence)
        
        return occurrences
    
    async def _fetch_obis_occurrences(self, species_name: str) -> List[SpeciesOccurrence]:
        """Obter dados do OBIS"""
        occurrences = []
        base_url = self.config['obis_api_url']
        
        async with aiohttp.ClientSession() as session:
            url = f"{base_url}/occurrence"
            params = {
                'scientificname': species_name,
                'geometry': f"POLYGON(({self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['min_lat']}, {self.config['angola_bounds']['max_lon']} {self.config['angola_bounds']['min_lat']}, {self.config['angola_bounds']['max_lon']} {self.config['angola_bounds']['max_lat']}, {self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['max_lat']}, {self.config['angola_bounds']['min_lon']} {self.config['angola_bounds']['min_lat']}))",
                'size': self.config['max_occurrences']
            }
            
            try:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        for record in data.get('results', []):
                            if 'decimalLatitude' in record and 'decimalLongitude' in record:
                                occurrence = SpeciesOccurrence(
                                    species_name=species_name,
                                    latitude=record['decimalLatitude'],
                                    longitude=record['decimalLongitude'],
                                    source='obis',
                                    confidence=1.0
                                )
                                occurrences.append(occurrence)
            except Exception as e:
                logger.warning(f"⚠️ Erro ao consultar OBIS: {str(e)}")
        
        return occurrences
    
    def _filter_occurrences_angola(self, occurrences: List[SpeciesOccurrence]) -> List[SpeciesOccurrence]:
        """Filtrar ocorrências para a região de Angola"""
        bounds = self.config['angola_bounds']
        filtered = []
        
        for occ in occurrences:
            if (bounds['min_lat'] <= occ.latitude <= bounds['max_lat'] and 
                bounds['min_lon'] <= occ.longitude <= bounds['max_lon']):
                filtered.append(occ)
        
        return filtered
    
    def add_environmental_layer(self, layer: EnvironmentalLayer) -> None:
        """
        📊 Adicionar camada ambiental para modelação
        
        Args:
            layer: Camada ambiental com metadados
        """
        self.environmental_layers[layer.name] = layer
        logger.info(f"✅ Camada ambiental '{layer.name}' adicionada")
    
    def generate_background_points(self, n_points: Optional[int] = None) -> List[Tuple[float, float]]:
        """
        🎲 Gerar pontos de background para modelação MaxEnt
        
        Args:
            n_points: Número de pontos a gerar
            
        Returns:
            Lista de coordenadas (lat, lon)
        """
        if n_points is None:
            n_points = self.config['n_background_points']
        
        bounds = self.config['angola_bounds']
        
        # Gerar pontos aleatórios dentro dos limites de Angola
        lats = np.random.uniform(bounds['min_lat'], bounds['max_lat'], n_points)
        lons = np.random.uniform(bounds['min_lon'], bounds['max_lon'], n_points)
        
        background_points = list(zip(lats, lons))
        
        logger.info(f"🎲 Gerados {len(background_points)} pontos de background")
        return background_points
    
    def extract_environmental_values(
        self, 
        coordinates: List[Tuple[float, float]]
    ) -> pd.DataFrame:
        """
        🌍 Extrair valores ambientais para coordenadas específicas
        
        Args:
            coordinates: Lista de coordenadas (lat, lon)
            
        Returns:
            DataFrame com valores ambientais
        """
        logger.info(f"🌍 Extraindo valores ambientais para {len(coordinates)} pontos")
        
        # Por agora, usar valores simulados baseados em dados reais de Angola
        # Em implementação futura, integrar com rasters reais
        
        data = []
        for lat, lon in coordinates:
            # Simular valores ambientais baseados na localização
            env_values = self._simulate_environmental_values(lat, lon)
            env_values['latitude'] = lat
            env_values['longitude'] = lon
            data.append(env_values)
        
        df = pd.DataFrame(data)
        logger.info(f"✅ Valores ambientais extraídos para {len(df)} pontos")
        return df
    
    def _simulate_environmental_values(self, lat: float, lon: float) -> Dict[str, float]:
        """Simular valores ambientais baseados na localização"""
        # Valores simulados mas realistas para Angola
        
        # Temperatura do mar (baseada na latitude - mais quente no norte)
        sst = 24 + (lat + 18) * 0.3 + np.random.normal(0, 1)
        
        # Salinidade (varia com proximidade à costa)
        salinity = 35 + np.random.normal(0, 0.5)
        
        # Clorofila-a (maior perto da costa devido ao upwelling)
        # Costa de Angola tem upwelling forte
        coastal_distance = min(abs(lon - 13), abs(lat + 12))  # Aproximação
        chlorophyll = max(0.1, 2.0 - coastal_distance * 0.1 + np.random.normal(0, 0.2))
        
        # Profundidade (simulada baseada na distância da costa)
        bathymetry = -50 - coastal_distance * 100 + np.random.normal(0, 20)
        
        # Velocidade da corrente
        current_speed = 0.2 + np.random.normal(0, 0.1)
        
        # Produtividade primária
        primary_productivity = chlorophyll * 50 + np.random.normal(0, 10)
        
        return {
            'sea_surface_temperature': max(20, min(30, sst)),
            'salinity': max(30, min(40, salinity)),
            'chlorophyll_a': max(0.01, chlorophyll),
            'bathymetry': min(-10, bathymetry),
            'current_speed': max(0, current_speed),
            'primary_productivity': max(0, primary_productivity)
        }
    
    async def train_maxent_model(
        self, 
        species_name: str, 
        occurrences: Optional[List[SpeciesOccurrence]] = None
    ) -> MaxEntResult:
        """
        🎯 Treinar modelo MaxEnt para uma espécie
        
        Args:
            species_name: Nome da espécie
            occurrences: Lista de ocorrências (opcional, obtém automaticamente se não fornecida)
            
        Returns:
            Resultado da modelação MaxEnt
        """
        logger.info(f"🎯 Iniciando treino do modelo MaxEnt para {species_name}")
        
        # Obter ocorrências se não fornecidas
        if occurrences is None:
            occurrences = await self.fetch_species_occurrences(species_name, "gbif")
            if not occurrences:
                occurrences = await self.fetch_species_occurrences(species_name, "obis")
        
        if len(occurrences) < 10:
            raise ValueError(f"❌ Insuficientes ocorrências ({len(occurrences)}) para treinar modelo")
        
        # Preparar dados de treino
        presence_coords = [(occ.latitude, occ.longitude) for occ in occurrences]
        background_coords = self.generate_background_points()
        
        # Extrair valores ambientais
        presence_env = self.extract_environmental_values(presence_coords)
        background_env = self.extract_environmental_values(background_coords)
        
        # Preparar dataset
        presence_env['presence'] = 1
        background_env['presence'] = 0
        
        # Combinar dados
        full_dataset = pd.concat([presence_env, background_env], ignore_index=True)
        
        # Preparar features e target
        feature_cols = [col for col in full_dataset.columns 
                       if col not in ['latitude', 'longitude', 'presence']]
        X = full_dataset[feature_cols]
        y = full_dataset['presence']
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.config['test_size'], 
            random_state=self.config['random_state'], stratify=y
        )
        
        # Treinar modelo (Random Forest como aproximação ao MaxEnt)
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=self.config['random_state'],
            class_weight='balanced'
        )
        
        logger.info("🔄 Treinando modelo...")
        model.fit(X_train, y_train)
        
        # Avaliar modelo
        train_pred = model.predict_proba(X_train)[:, 1]
        test_pred = model.predict_proba(X_test)[:, 1]
        
        auc_score = roc_auc_score(y_test, test_pred)
        train_accuracy = model.score(X_train, y_train)
        test_accuracy = model.score(X_test, y_test)
        
        # Importância das features
        feature_importance = dict(zip(feature_cols, model.feature_importances_))
        
        # Gerar mapa de predição
        prediction_map = self._generate_prediction_map(model, feature_cols)
        
        # Salvar modelo
        model_path = self.models_dir / f"{species_name.replace(' ', '_')}_maxent_model.pkl"
        
        result = MaxEntResult(
            species_name=species_name,
            auc_score=auc_score,
            training_accuracy=train_accuracy,
            test_accuracy=test_accuracy,
            feature_importance=feature_importance,
            prediction_map=prediction_map,
            model_path=str(model_path),
            created_at=datetime.now()
        )
        
        # Armazenar modelo
        self.models[species_name] = model
        
        logger.info(f"✅ Modelo MaxEnt treinado com sucesso!")
        logger.info(f"📊 AUC: {auc_score:.3f}, Precisão Teste: {test_accuracy:.3f}")
        
        return result
    
    def _generate_prediction_map(
        self, 
        model, 
        feature_cols: List[str], 
        resolution: float = 0.1
    ) -> np.ndarray:
        """Gerar mapa de predição de adequação de habitat"""
        bounds = self.config['angola_bounds']
        
        # Criar grid de predição
        lats = np.arange(bounds['min_lat'], bounds['max_lat'], resolution)
        lons = np.arange(bounds['min_lon'], bounds['max_lon'], resolution)
        
        lat_grid, lon_grid = np.meshgrid(lats, lons)
        coords = list(zip(lat_grid.ravel(), lon_grid.ravel()))
        
        # Extrair valores ambientais para o grid
        env_data = self.extract_environmental_values(coords)
        
        # Fazer predições
        predictions = model.predict_proba(env_data[feature_cols])[:, 1]
        
        # Reformatar como mapa
        prediction_map = predictions.reshape(lat_grid.shape)
        
        return prediction_map
    
    def visualize_results(self, result: MaxEntResult, save_path: Optional[str] = None) -> None:
        """
        📊 Visualizar resultados da modelação MaxEnt
        
        Args:
            result: Resultado da modelação
            save_path: Caminho para salvar a visualização
        """
        logger.info(f"📊 Criando visualização para {result.species_name}")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'Modelação MaxEnt - {result.species_name}', fontsize=16, fontweight='bold')
        
        # 1. Mapa de adequação de habitat
        ax1 = axes[0, 0]
        im1 = ax1.imshow(result.prediction_map, cmap='viridis', aspect='auto')
        ax1.set_title('Adequação de Habitat')
        ax1.set_xlabel('Longitude')
        ax1.set_ylabel('Latitude')
        plt.colorbar(im1, ax=ax1, label='Probabilidade de Presença')
        
        # 2. Importância das variáveis
        ax2 = axes[0, 1]
        features = list(result.feature_importance.keys())
        importance = list(result.feature_importance.values())
        bars = ax2.barh(features, importance)
        ax2.set_title('Importância das Variáveis Ambientais')
        ax2.set_xlabel('Importância')
        
        # Colorir barras
        colors = plt.cm.viridis(np.linspace(0, 1, len(bars)))
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # 3. Métricas do modelo
        ax3 = axes[1, 0]
        metrics = ['AUC', 'Precisão Treino', 'Precisão Teste']
        values = [result.auc_score, result.training_accuracy, result.test_accuracy]
        bars3 = ax3.bar(metrics, values, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
        ax3.set_title('Métricas de Performance')
        ax3.set_ylabel('Score')
        ax3.set_ylim(0, 1)
        
        # Adicionar valores nas barras
        for bar, value in zip(bars3, values):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        # 4. Informações do modelo
        ax4 = axes[1, 1]
        ax4.axis('off')
        info_text = f"""
        Espécie: {result.species_name}
        
        Métricas:
        • AUC: {result.auc_score:.3f}
        • Precisão Treino: {result.training_accuracy:.3f}
        • Precisão Teste: {result.test_accuracy:.3f}
        
        Variável Mais Importante:
        {max(result.feature_importance.keys(), key=result.feature_importance.get)}
        
        Data de Criação:
        {result.created_at.strftime('%d/%m/%Y %H:%M')}
        """
        ax4.text(0.1, 0.9, info_text, transform=ax4.transAxes, fontsize=10,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray'))
        
        plt.tight_layout()
        
        # Salvar se especificado
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"💾 Visualização salva em: {save_path}")
        
        plt.show()
    
    def get_species_prediction(
        self, 
        species_name: str, 
        latitude: float, 
        longitude: float
    ) -> Dict[str, float]:
        """
        🎯 Obter predição para uma localização específica
        
        Args:
            species_name: Nome da espécie
            latitude: Latitude
            longitude: Longitude
            
        Returns:
            Predição de adequação de habitat
        """
        if species_name not in self.models:
            raise ValueError(f"❌ Modelo para {species_name} não encontrado")
        
        model = self.models[species_name]
        
        # Extrair valores ambientais
        env_values = self.extract_environmental_values([(latitude, longitude)])
        feature_cols = [col for col in env_values.columns 
                       if col not in ['latitude', 'longitude']]
        
        # Fazer predição
        probability = model.predict_proba(env_values[feature_cols])[0, 1]
        prediction = model.predict(env_values[feature_cols])[0]
        
        return {
            'species': species_name,
            'latitude': latitude,
            'longitude': longitude,
            'suitability_probability': float(probability),
            'predicted_presence': bool(prediction),
            'confidence': 'high' if probability > 0.7 or probability < 0.3 else 'medium'
        }
    
    def export_results(self, result: MaxEntResult, format: str = 'json') -> str:
        """
        💾 Exportar resultados da modelação
        
        Args:
            result: Resultado da modelação
            format: Formato de exportação ('json', 'csv')
            
        Returns:
            Caminho do ficheiro exportado
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        species_clean = result.species_name.replace(' ', '_')
        
        if format.lower() == 'json':
            export_path = self.output_dir / f"{species_clean}_maxent_{timestamp}.json"
            
            export_data = {
                'species_name': result.species_name,
                'model_metadata': {
                    'auc_score': result.auc_score,
                    'training_accuracy': result.training_accuracy,
                    'test_accuracy': result.test_accuracy,
                    'created_at': result.created_at.isoformat()
                },
                'feature_importance': result.feature_importance,
                'model_path': result.model_path
            }
            
            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
                
        else:
            raise ValueError(f"❌ Formato {format} não suportado")
        
        logger.info(f"💾 Resultados exportados para: {export_path}")
        return str(export_path)

# Exemplo de uso
if __name__ == "__main__":
    async def main():
        # Inicializar serviço
        maxent_service = MaxEntService()
        
        # Exemplo com espécie marinha comum em Angola
        species_name = "Sardinella aurita"  # Sardinha
        
        logger.info(f"🐟 Iniciando modelação MaxEnt para {species_name}")
        
        try:
            # Treinar modelo
            result = await maxent_service.train_maxent_model(species_name)
            
            # Visualizar resultados
            maxent_service.visualize_results(result)
            
            # Fazer predição para Luanda (coordenadas aproximadas)
            luanda_prediction = maxent_service.get_species_prediction(
                species_name, -8.8383, 13.2344
            )
            logger.info(f"🎯 Predição para Luanda: {luanda_prediction}")
            
            # Exportar resultados
            export_path = maxent_service.export_results(result)
            logger.info(f"💾 Resultados exportados: {export_path}")
            
        except Exception as e:
            logger.info(f"❌ Erro: {str(e)}")
    
    # Executar exemplo
    asyncio.run(main())
