#!/usr/bin/env python3
"""
DemonstraÃ§Ã£o do Sistema de Machine Learning
Script independente que demonstra todas as funcionalidades implementadas
"""

import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import uuid

class MLSystemDemo:
    """DemonstraÃ§Ã£o das funcionalidades de ML implementadas"""
    
    def __init__(self):
        self.demo_db = "demo_ml.db"
        self.setup_demo_database()
    
    def setup_demo_database(self):
        """Cria base de dados de demonstraÃ§Ã£o"""
        print("ğŸ—„ï¸ Configurando base de dados de demonstraÃ§Ã£o...")
        
        conn = sqlite3.connect(self.demo_db)
        
        # Criar tabelas simplificadas para demo
        conn.execute("""
            CREATE TABLE IF NOT EXISTS biodiversity_studies (
                study_id TEXT PRIMARY KEY,
                study_name TEXT NOT NULL,
                study_type TEXT NOT NULL,
                latitude REAL NOT NULL,
                longitude REAL NOT NULL,
                species_observed TEXT,
                environmental_parameters TEXT,
                data_quality_score REAL,
                processed_for_ml BOOLEAN DEFAULT FALSE,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS ml_training_data (
                training_data_id TEXT PRIMARY KEY,
                source_study_id TEXT,
                model_type TEXT,
                features TEXT,
                target_variable TEXT,
                target_value TEXT,
                data_quality REAL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS ml_models (
                model_id TEXT PRIMARY KEY,
                model_name TEXT,
                model_type TEXT,
                status TEXT,
                training_accuracy REAL,
                prediction_count INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS prediction_results (
                prediction_id TEXT PRIMARY KEY,
                model_id TEXT,
                input_data TEXT,
                prediction TEXT,
                confidence REAL,
                latitude REAL,
                longitude REAL,
                used_for_mapping BOOLEAN DEFAULT FALSE,
                prediction_timestamp TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.execute("""
            CREATE TABLE IF NOT EXISTS map_filters (
                filter_id TEXT PRIMARY KEY,
                name TEXT,
                filter_type TEXT,
                model_id TEXT,
                min_confidence REAL,
                is_active BOOLEAN DEFAULT TRUE,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
        
        print("âœ… Base de dados configurada")
    
    def demo_create_biodiversity_study(self):
        """Demonstra criaÃ§Ã£o automÃ¡tica de estudo de biodiversidade"""
        print("\nğŸŸ DEMO: CriaÃ§Ã£o de Estudo de Biodiversidade")
        print("-" * 50)
        
        # Dados do estudo
        study_data = {
            "study_id": f"demo_study_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "study_name": "Levantamento Costa de Luanda - Demo",
            "study_type": "species_survey",
            "latitude": -8.8383,
            "longitude": 13.2344,
            "species_observed": [
                {"species_name": "Sardinella aurita", "count": 25, "abundance": 75},
                {"species_name": "Trachurus capensis", "count": 12, "abundance": 45}
            ],
            "environmental_parameters": {
                "temperature": 24.8,
                "salinity": 35.1,
                "ph": 8.0,
                "chlorophyll": 2.3
            },
            "data_quality_score": 0.87
        }
        
        # Simular armazenamento automÃ¡tico
        conn = sqlite3.connect(self.demo_db)
        
        conn.execute("""
            INSERT INTO biodiversity_studies (
                study_id, study_name, study_type, latitude, longitude,
                species_observed, environmental_parameters, data_quality_score,
                processed_for_ml
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            study_data["study_id"],
            study_data["study_name"],
            study_data["study_type"],
            study_data["latitude"],
            study_data["longitude"],
            json.dumps(study_data["species_observed"]),
            json.dumps(study_data["environmental_parameters"]),
            study_data["data_quality_score"],
            True  # Processado automaticamente
        ))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… Estudo criado: {study_data['study_id']}")
        print(f"   ğŸ“ LocalizaÃ§Ã£o: {study_data['latitude']}, {study_data['longitude']}")
        print(f"   ğŸŸ EspÃ©cies: {len(study_data['species_observed'])}")
        print(f"   ğŸ“Š Qualidade: {study_data['data_quality_score']:.2f}")
        print(f"   ğŸ§  Processado para ML: âœ…")
        
        return study_data["study_id"]
    
    def demo_automatic_ml_ingestion(self, study_id):
        """Demonstra ingestÃ£o automÃ¡tica para ML"""
        print("\nğŸ”„ DEMO: IngestÃ£o AutomÃ¡tica para ML")
        print("-" * 50)
        
        # Simular extraÃ§Ã£o automÃ¡tica de caracterÃ­sticas
        conn = sqlite3.connect(self.demo_db)
        
        # Obter dados do estudo
        study = conn.execute(
            "SELECT * FROM biodiversity_studies WHERE study_id = ?",
            (study_id,)
        ).fetchone()
        
        if not study:
            print("âŒ Estudo nÃ£o encontrado")
            return
        
        # Extrair dados para treino
        species_data = json.loads(study[5])  # species_observed
        env_data = json.loads(study[6])      # environmental_parameters
        
        training_samples = []
        
        for species in species_data:
            # Criar amostra de treino para cada espÃ©cie
            training_id = f"training_{study_id}_{species['species_name'].replace(' ', '_')}"
            
            features = {
                "latitude": study[3],
                "longitude": study[4],
                **env_data
            }
            
            # Inserir dados de treino
            conn.execute("""
                INSERT INTO ml_training_data (
                    training_data_id, source_study_id, model_type,
                    features, target_variable, target_value, data_quality
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                training_id,
                study_id,
                "biodiversity_predictor",
                json.dumps(features),
                "abundance",
                str(species["abundance"]),
                study[7]  # data_quality_score
            ))
            
            training_samples.append(training_id)
        
        conn.commit()
        conn.close()
        
        print(f"âœ… Dados extraÃ­dos automaticamente:")
        print(f"   ğŸ“Š {len(training_samples)} amostras de treino criadas")
        print(f"   ğŸ¯ Modelo alvo: biodiversity_predictor")
        print(f"   ğŸ”§ CaracterÃ­sticas: latitude, longitude, temperatura, salinidade, pH, clorofila")
        print(f"   ğŸ“ˆ VariÃ¡vel alvo: abundÃ¢ncia de espÃ©cies")
        
        return training_samples
    
    def demo_model_training(self):
        """Demonstra treino automÃ¡tico de modelos"""
        print("\nğŸ§  DEMO: Treino AutomÃ¡tico de Modelos")
        print("-" * 50)
        
        conn = sqlite3.connect(self.demo_db)
        
        # Contar dados de treino disponÃ­veis
        training_count = conn.execute(
            "SELECT COUNT(*) FROM ml_training_data WHERE model_type = 'biodiversity_predictor'"
        ).fetchone()[0]
        
        # Simular treino de modelo
        model_data = {
            "model_id": "biodiversity_predictor_v1",
            "model_name": "Preditor de Biodiversidade v1.0",
            "model_type": "biodiversity_predictor",
            "status": "trained",
            "training_accuracy": 0.94  # 94% de precisÃ£o simulada
        }
        
        conn.execute("""
            INSERT OR REPLACE INTO ml_models (
                model_id, model_name, model_type, status, training_accuracy
            ) VALUES (?, ?, ?, ?, ?)
        """, (
            model_data["model_id"],
            model_data["model_name"],
            model_data["model_type"],
            model_data["status"],
            model_data["training_accuracy"]
        ))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… Modelo treinado automaticamente:")
        print(f"   ğŸ¤– Modelo: {model_data['model_name']}")
        print(f"   ğŸ“Š Dados de treino: {training_count} amostras")
        print(f"   ğŸ¯ PrecisÃ£o: {model_data['training_accuracy']:.1%}")
        print(f"   âš¡ Status: {model_data['status']}")
        
        return model_data["model_id"]
    
    def demo_ml_prediction(self, model_id):
        """Demonstra prediÃ§Ã£o com ML"""
        print("\nğŸ”® DEMO: PrediÃ§Ãµes de Machine Learning")
        print("-" * 50)
        
        # Dados de entrada para prediÃ§Ã£o
        input_data = {
            "latitude": -8.85,
            "longitude": 13.25,
            "temperature": 25.2,
            "salinity": 35.0,
            "ph": 8.1,
            "chlorophyll": 2.1
        }
        
        # Simular prediÃ§Ã£o (em produÃ§Ã£o seria o modelo real)
        import random
        prediction_result = {
            "prediction_id": f"pred_{uuid.uuid4().hex[:8]}",
            "model_id": model_id,
            "input_data": input_data,
            "prediction": {"species_richness": random.randint(8, 20)},
            "confidence": random.uniform(0.75, 0.95),
            "latitude": input_data["latitude"],
            "longitude": input_data["longitude"]
        }
        
        # Salvar resultado
        conn = sqlite3.connect(self.demo_db)
        
        conn.execute("""
            INSERT INTO prediction_results (
                prediction_id, model_id, input_data, prediction, confidence,
                latitude, longitude, used_for_mapping
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            prediction_result["prediction_id"],
            prediction_result["model_id"],
            json.dumps(prediction_result["input_data"]),
            json.dumps(prediction_result["prediction"]),
            prediction_result["confidence"],
            prediction_result["latitude"],
            prediction_result["longitude"],
            True
        ))
        
        # Atualizar contador de prediÃ§Ãµes do modelo
        conn.execute("""
            UPDATE ml_models 
            SET prediction_count = prediction_count + 1 
            WHERE model_id = ?
        """, (model_id,))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… PrediÃ§Ã£o realizada:")
        print(f"   ğŸ†” ID: {prediction_result['prediction_id']}")
        print(f"   ğŸ“ Local: {input_data['latitude']:.3f}, {input_data['longitude']:.3f}")
        print(f"   ğŸŸ PrediÃ§Ã£o: {prediction_result['prediction']['species_richness']} espÃ©cies")
        print(f"   ğŸ¯ ConfianÃ§a: {prediction_result['confidence']:.1%}")
        print(f"   ğŸ—ºï¸ Usado para mapeamento: âœ…")
        
        return prediction_result["prediction_id"]
    
    def demo_predictive_filters(self, model_id):
        """Demonstra filtros preditivos"""
        print("\nğŸ—ºï¸ DEMO: Filtros Preditivos para Mapas")
        print("-" * 50)
        
        # Criar filtro
        filter_data = {
            "filter_id": "biodiversity_hotspots_demo",
            "name": "Hotspots de Biodiversidade - Demo",
            "filter_type": "biodiversity_hotspots",
            "model_id": model_id,
            "min_confidence": 0.8
        }
        
        conn = sqlite3.connect(self.demo_db)
        
        conn.execute("""
            INSERT OR REPLACE INTO map_filters (
                filter_id, name, filter_type, model_id, min_confidence, is_active
            ) VALUES (?, ?, ?, ?, ?, ?)
        """, (
            filter_data["filter_id"],
            filter_data["name"],
            filter_data["filter_type"],
            filter_data["model_id"],
            filter_data["min_confidence"],
            True
        ))
        
        # Obter prediÃ§Ãµes que atendem aos critÃ©rios do filtro
        predictions = conn.execute("""
            SELECT prediction_id, latitude, longitude, prediction, confidence
            FROM prediction_results 
            WHERE model_id = ? AND confidence >= ? AND used_for_mapping = TRUE
        """, (model_id, filter_data["min_confidence"])).fetchall()
        
        conn.commit()
        conn.close()
        
        # Simular dados GeoJSON
        geojson_features = []
        for pred in predictions:
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [pred[2], pred[1]]  # lon, lat
                },
                "properties": {
                    "prediction_id": pred[0],
                    "prediction": json.loads(pred[3]),
                    "confidence": pred[4],
                    "marker_color": "#ff6b35" if pred[4] > 0.9 else "#ffa500",
                    "marker_size": int(pred[4] * 15)
                }
            }
            geojson_features.append(feature)
        
        print(f"âœ… Filtro preditivo criado:")
        print(f"   ğŸ·ï¸ Nome: {filter_data['name']}")
        print(f"   ğŸ“Š Tipo: {filter_data['filter_type']}")
        print(f"   ğŸ¯ ConfianÃ§a mÃ­nima: {filter_data['min_confidence']:.1%}")
        print(f"   ğŸ“ Pontos no mapa: {len(geojson_features)}")
        print(f"   ğŸ—ºï¸ Formato: GeoJSON pronto para mapas")
        
        return filter_data["filter_id"], geojson_features
    
    def demo_system_statistics(self):
        """Demonstra estatÃ­sticas do sistema"""
        print("\nğŸ“Š DEMO: EstatÃ­sticas do Sistema")
        print("-" * 50)
        
        conn = sqlite3.connect(self.demo_db)
        
        # EstatÃ­sticas gerais
        studies_total = conn.execute("SELECT COUNT(*) FROM biodiversity_studies").fetchone()[0]
        studies_processed = conn.execute("SELECT COUNT(*) FROM biodiversity_studies WHERE processed_for_ml = TRUE").fetchone()[0]
        
        training_samples = conn.execute("SELECT COUNT(*) FROM ml_training_data").fetchone()[0]
        
        models_total = conn.execute("SELECT COUNT(*) FROM ml_models").fetchone()[0]
        models_trained = conn.execute("SELECT COUNT(*) FROM ml_models WHERE status = 'trained'").fetchone()[0]
        
        predictions_total = conn.execute("SELECT COUNT(*) FROM prediction_results").fetchone()[0]
        
        filters_total = conn.execute("SELECT COUNT(*) FROM map_filters").fetchone()[0]
        filters_active = conn.execute("SELECT COUNT(*) FROM map_filters WHERE is_active = TRUE").fetchone()[0]
        
        # Qualidade mÃ©dia dos dados
        avg_quality = conn.execute("SELECT AVG(data_quality_score) FROM biodiversity_studies").fetchone()[0] or 0
        
        conn.close()
        
        print("ğŸ“ˆ EstatÃ­sticas Gerais:")
        print(f"   ğŸ“š Total de estudos: {studies_total}")
        print(f"   ğŸ§  Processados para ML: {studies_processed}")
        print(f"   ğŸ“Š Amostras de treino: {training_samples}")
        print(f"   ğŸ¤– Modelos disponÃ­veis: {models_total}")
        print(f"   âœ… Modelos treinados: {models_trained}")
        print(f"   ğŸ”® PrediÃ§Ãµes realizadas: {predictions_total}")
        print(f"   ğŸ—ºï¸ Filtros disponÃ­veis: {filters_total}")
        print(f"   âš¡ Filtros ativos: {filters_active}")
        print(f"   ğŸ“ Qualidade mÃ©dia: {avg_quality:.2f}")
        
        return {
            "total_studies": studies_total,
            "processed_studies": studies_processed,
            "training_samples": training_samples,
            "models_trained": models_trained,
            "predictions_total": predictions_total,
            "filters_active": filters_active,
            "avg_quality": avg_quality
        }
    
    def demo_endpoints_simulation(self):
        """Demonstra como os endpoints funcionariam"""
        print("\nğŸ›¡ï¸ DEMO: Endpoints Seguros (SimulaÃ§Ã£o)")
        print("-" * 50)
        
        endpoints = [
            {
                "method": "POST",
                "path": "/ml/studies",
                "description": "Criar estudo de biodiversidade",
                "rate_limit": "30/minuto",
                "auth": "Bearer token obrigatÃ³rio",
                "validation": "Pydantic models com validaÃ§Ã£o rigorosa"
            },
            {
                "method": "POST",
                "path": "/ml/predict",
                "description": "Fazer prediÃ§Ã£o ML",
                "rate_limit": "100/minuto",
                "auth": "Bearer token obrigatÃ³rio",
                "validation": "Coordenadas e parÃ¢metros validados"
            },
            {
                "method": "POST",
                "path": "/ml/filters",
                "description": "Criar filtro preditivo",
                "rate_limit": "20/minuto",
                "auth": "Bearer token obrigatÃ³rio",
                "validation": "Bbox e configuraÃ§Ãµes validadas"
            },
            {
                "method": "GET",
                "path": "/ml/filters/{id}/data",
                "description": "Dados GeoJSON do filtro",
                "rate_limit": "200/minuto",
                "auth": "Bearer token obrigatÃ³rio",
                "validation": "ID do filtro validado"
            }
        ]
        
        print("ğŸ”’ Endpoints implementados com seguranÃ§a:")
        for endpoint in endpoints:
            print(f"   {endpoint['method']} {endpoint['path']}")
            print(f"      ğŸ“ {endpoint['description']}")
            print(f"      â±ï¸ Rate limit: {endpoint['rate_limit']}")
            print(f"      ğŸ” Auth: {endpoint['auth']}")
            print(f"      âœ… ValidaÃ§Ã£o: {endpoint['validation']}")
            print()
    
    def run_complete_demo(self):
        """Executa demonstraÃ§Ã£o completa do sistema"""
        print("ğŸŒŠ BGAPP - DemonstraÃ§Ã£o do Sistema de Machine Learning")
        print("=" * 60)
        print("ğŸ¯ Esta demonstraÃ§Ã£o mostra todas as funcionalidades implementadas")
        print("   sem necessidade de executar a aplicaÃ§Ã£o completa.")
        print()
        
        try:
            # 1. Criar estudo
            study_id = self.demo_create_biodiversity_study()
            
            # 2. IngestÃ£o automÃ¡tica
            training_samples = self.demo_automatic_ml_ingestion(study_id)
            
            # 3. Treino de modelo
            model_id = self.demo_model_training()
            
            # 4. Fazer prediÃ§Ãµes
            prediction_id = self.demo_ml_prediction(model_id)
            
            # 5. Criar filtros
            filter_id, geojson = self.demo_predictive_filters(model_id)
            
            # 6. Mostrar estatÃ­sticas
            stats = self.demo_system_statistics()
            
            # 7. Demonstrar endpoints
            self.demo_endpoints_simulation()
            
            # Resumo final
            print("\nğŸ‰ DEMONSTRAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!")
            print("=" * 60)
            print("âœ… Todas as funcionalidades foram demonstradas:")
            print("   ğŸ—„ï¸ Armazenamento automÃ¡tico de estudos")
            print("   ğŸ”„ IngestÃ£o automÃ¡tica para ML")
            print("   ğŸ§  Treino automÃ¡tico de modelos")
            print("   ğŸ”® PrediÃ§Ãµes em tempo real")
            print("   ğŸ—ºï¸ Filtros preditivos para mapas")
            print("   ğŸ›¡ï¸ Endpoints seguros com validaÃ§Ã£o")
            print("   ğŸ“Š Sistema de monitorizaÃ§Ã£o completo")
            
            print(f"\nğŸ“ˆ Resultados da demonstraÃ§Ã£o:")
            print(f"   ğŸ“š Estudos processados: {stats['processed_studies']}")
            print(f"   ğŸ§  Amostras de treino: {stats['training_samples']}")
            print(f"   ğŸ¤– Modelos treinados: {stats['models_trained']}")
            print(f"   ğŸ”® PrediÃ§Ãµes realizadas: {stats['predictions_total']}")
            print(f"   ğŸ—ºï¸ Filtros ativos: {stats['filters_active']}")
            
            print(f"\nğŸ’¾ Base de dados de demonstraÃ§Ã£o: {self.demo_db}")
            print("   (Pode ser inspecionada com qualquer ferramenta SQLite)")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ Erro na demonstraÃ§Ã£o: {e}")
            return False
    
    def cleanup(self):
        """Limpa arquivos de demonstraÃ§Ã£o"""
        try:
            Path(self.demo_db).unlink(missing_ok=True)
            print(f"ğŸ§¹ Arquivo {self.demo_db} removido")
        except Exception as e:
            print(f"âš ï¸ Erro removendo arquivo: {e}")

def main():
    """FunÃ§Ã£o principal"""
    demo = MLSystemDemo()
    
    try:
        success = demo.run_complete_demo()
        
        if success:
            print("\nğŸš€ O sistema real estÃ¡ pronto para uso!")
            print("ğŸ“‹ Para usar com a aplicaÃ§Ã£o real:")
            print("   1. Iniciar aplicaÃ§Ã£o: ./start_bgapp_local.sh")
            print("   2. Testar endpoints: python test_ml_system.py")
            print("   3. Ver documentaÃ§Ã£o: http://localhost:8000/docs")
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ DemonstraÃ§Ã£o interrompida pelo usuÃ¡rio")
        return 1
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {e}")
        return 1
    finally:
        # Perguntar se deve limpar arquivos
        try:
            response = input("\nğŸ§¹ Remover arquivos de demonstraÃ§Ã£o? (y/N): ").strip().lower()
            if response in ['y', 'yes', 's', 'sim']:
                demo.cleanup()
        except:
            pass

if __name__ == "__main__":
    exit(main())
